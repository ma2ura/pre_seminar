---
title: "松浦プレゼミの紹介"
author: "松浦 総一"
format:
  revealjs:
    html-math-method: katex
    theme: default
    transition: convex
editor: visual
execute:
  # echo: false
  message : false
  warning: false
  fig-width: 10
  fig-height: 5
---

```{r setup}
#| echo: false
library(tidyverse)
library(ggthemes)
library(ggpubr)
library(plotly)
library(patchwork)
# ggplotの設定を mysytle に収納0
mystyle <- list (#  ggplotのテーマ
  theme_calc(), # ggthemesパッケージ
  scale_colour_calc(), # ggthemesパッケージ
  theme(
    text = element_text(
      size=12,  #  フォントサイズ
      family = "HiraKakuProN-W3" # ヒラギノフォント
    )
  ),
#  scale_y_continuous(expand = c(0,0)),
  scale_x_continuous(expand = c(0,0))
)
```

# 第0章 プレゼミとは？

## プレゼミの概要

松浦プレゼミ2023では、データに強い経営学部生となるため、データ分析のツールとしてもはやデファクトスタンダードとなっている(いいすぎ)プログラミング言語**R**を使って、様々な分析を行うためのスキルの修得を目指します。
株価データや会計データ、POSデータといったデータベース以外にも、自分で集めたアンケートのデータや、Webスクレイピングで集めたデータなど、様々なデータを分析することができるスキルは、会計・ファイナンスだけでなく、組織、戦略、マーケティングと様々な分野で役に立つはずです。

またRで分析した結果をレポートにまとめる際に有用なツールとして、**Quarto**を勉強します。
**Quarto**(クアルト)とは、Markdown記法で書かれた文章の中に、RだけでなくPythonなど他の言語も組み込める便利なツールです。


## なぜR/Quarto？

:::: {.columns}

::: {.column width="50%"}

**メリット**

- ぜんぶ**無料**
- 学習しやすい・教材たくさん
- 作業履歴が残る
- 卒業後も使える (大学で購入しているSPSSとかStataは買うと高い)
- 勉強しやすい
- なんかかっこいい
:::

::: {.column width="50%"}
**デメリット**

- データを命令文で操作するので、見た目にわかりにくい。
- マウスではなくキーボードで文字を入力してデータを操作するので、キーボード入力に慣れてないと辛い。
- R言語の文法と単語を覚えなきゃいけない
:::

::::





## MS Excelだとダメなの？

:::: {.columns}

::: {.column width="50%"}

**メリット**

- みんな使ってる。
- 就職しても使いそう
- 画面の表示が理解しやすい

:::

::: {.column width="50%"}
**デメリット**

- 有料 (立命館大学生のうちは無料で利用可能)
- マウスで何度もポチポチしないと何も出来ない
- 過去のExcelファイルを見て、自分が何をしたのか思い出せない
- Excelは大きなデータは扱えない_
- グラフのデザインが悪い
:::

::::




<!--
## IBM SPSSではどうか？

メリット

- MS Excelよりも統計分析に強いし正確
- ビジネスでよく利用されているらしい
- 難しい統計分析もいくつかクリックするだけで実行できる

デメリット

- かなり高い
- だいぶRに置き換えられてきている

## STATAではどうか？

- メリット：研究者はみんな使ってる。
- デメリット：高い。10万超え

-->

<!-- MS Excelは非常に役立つツールです。
ただ、データが大きくなるとExcelでは読み込めなくなる(Excelは縦に1,048,576行、横に16,384列が上限)が、RやPythonはPCのスペックに依存するものの、もっといける。

またExcelでグラフを作成しようとすると、メニューからグラフを選び、グラフの元となるデータを選択しといったように、メニューを何度もクリックすることになる。その結果、1週間後に同じグラフを作ろうと思っても、どうやって作ったのか思い出せなかったり、ちょっとデータを追加して新しいグラフを作ろうとすると、またいろんなところをポチポチする必要があり、再現可能性が低い。 -->

# Rでどんなことができる？

## 1. 楽にデータ操作ができる

Excelでは扱えないかなり大きなデータでも簡単にデータ操作ができます。
たとえば、データ分析の練習用データとして有名な`iris`データをいろいろ操作してみましょう。
`iris`は「あやめ」という花の花びらとがく片の長さと幅の4項目と3種類のあやめの分類名の1項目の合計5項目が150件収録されているデータベースです。Rには練習用に最初から入っているので、`head()`関数を使って`iris`の先頭の6行を読み込んでみます。

```{r iris}
head(iris) # 最初の6行だけ
```

---

このように、`Sepal.Length`、`Sepal.Width`、`Petal.Length`、`Petal.Width`、`Species`という5つの項目が入っていることが分かります。Sepalは花びらで、Petalはがく片です。まず花びらの長さ`Sepal.Length`の平均を求めてみましょう。平均を返す関数は`mean()`です。

```{r sepal_length}
mean(iris$Sepal.Length)
```

あやめの花びらの長さの平均は、`r mean(iris$Sepal.Length)`であることが分かりました。簡単ですね。

---


次に、あやめの種類を表す`Species`にはどんな種類があるのか見てみましょう。
`Species`に入っている種類を確認するには、`table()`関数を使ってみます。


```{r species_table}
table(iris$Species)
```
あやめの種類には、setosa、versicolor, virginicaがあり、それぞれ50個のデータがあることが分かります。


## 2. キレイなグラフが書ける。

では次にグラフを作成してみます。
最初に、花びらの長さのヒストグラムを書いてみます。
ここでは、非常に便利かつ簡単に美しいグラフを作成できるggplot2パッケージを使うために、`tidyverse`パッケージを導入します。

```{r graph_hist_sepal}
# install.packages("tidyverse") # 1回だけ実行
library(tidyverse)
g <- ggplot(iris) + aes(Sepal.Length) +
 geom_histogram()
print(g)
```

---

ヒストグラムの階級幅を変更したり、棒の数を変更するには、`geom_histogram()`の中で指定します。
例えば、階級幅を$0.5$でヒストグラムを作る場合は、`binwidth = 0.5`のように指定します。

```{r graph_hist_sepal_bin30}
g <- ggplot(iris) + aes(Sepal.Length) +
 geom_histogram(binwidth = .5)
print(g)
```

---

グラフが黒くて見づらいので、デザインをいじってみます。
`geom_histogram()`関数の中で、線を黒、中を薄青色に指定します。
```{r graph_hist_sepal_color}
g <- ggplot(iris) + aes(Sepal.Length) +
 geom_histogram(color="black", fill="lightblue",binwidth = .5)
print(g)
```

---

背景が地味なので、グラフを雑誌Economist風にしてみます。

```{r hist_economist}
g + theme_economist_white() + scale_colour_economist()
```

---

次は花びらの長さと幅の散布図を書いてみます。
`ggplot2`で散布図を書くためには、`aes()`で$x$軸と$y$軸を指定し、`geom_point()`で散布図を指定する。

```{r graph_sepal}
ggplot(iris) + aes(x = Sepal.Length, y = Sepal.Width) +
 geom_point() + theme_economist()
```
---

カテゴリーを表す変数を`group`と`colour`で指定すると、カテゴリーごとにグループ化して、色分けもしてくれます。ここでは花の種類を表す変数である`Species`ごとに色分けしてみます。

```{r graph_species}
g <- ggplot(iris) + # データセットirisを指定
  aes(x = Sepal.Length, # x軸 花びらの幅
      y = Sepal.Width, # y軸　花びらの幅
      group = Species, # あやめの種類ごとにグループ
      color = Species # あやめの種類ごとに色分け
      ) +
      geom_point() + # 散布図を指定
      theme_economist() # テーマをEconomistに
print(g)
```

---

操作できるグラフも作れます。
`plotly`パッケージを使えば簡単です。

```{r graph_plotly}
library(plotly)
ggplotly(g)
```

## 3. レポート・論文が作れる。

データを分析した結果を表や図としてレポートや論文に載せる場合、MS Excelで作成した図や表を、MS Wordにコピペしてませんか？
その場合、Wordで書いてたレポートの図表に少し修正を加えることになると、またExcelを開いて修正し、またコピペしたりしてませんか？
これはミスの元ですし、レポートを2週間後に読んだとして、その図表を作成したExcelがどこにあるのか、またどうやって作ったのか思い出せますか？
Rなら心配いりません。

**Quarto**や**Rmarkdown**を使ってMarkdownでレポートを書けば、文章作成と図表を同じ場所で作成できます。
ちなみに、このウェブサイトも**Quarto**を使って作成し、GitHubでウェブサイト公開してます。

---

例えば、`iris`データで、「あやめ」の種類ごとに、花びらの長さと幅の平均、中央値、標準偏差を計算し、それを表にしたいとしましょう。
Rなら簡単です。

```{r table_iris}
library(tidyverse)
iris %>%
  dplyr::group_by(Species) %>%
  dplyr::summarise(
    花びらの長さの平均 = mean(Sepal.Length),
    花びらの幅の平均 = mean(Sepal.Width),
    花びらの標準偏差 = sd(Sepal.Width)
  ) %>%
  knitr::kable(booktabs = TRUE)
```

---

たとえば、「あやめ」の種類ごとにがく片の長さが長いほど、花びらが長くなるかどうかを分析しようと回帰分析を行いたいとします。つまり以下のような回帰モデルを考えます（数式もこんなにキレイに書けます）。
$$
Sepal.Length = \alpha + \beta \times Petal.Length + \varepsilon
$$

---

この回帰モデルを最小二乗法(Ordinary Least Square Methos)で推定した結果を表にするときも次のように書けばできます。

```{r iris_regress_gtsummary}
library(gtsummary)
lm_fit <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
tbl_regression(lm_fit,
               type = "html",
               title = "Regression Results",
               exponentiate = FALSE,
               digits = list(all_continuous() ~ 2),
               add_estimate_to_reference_rows = TRUE,
               bold_p = TRUE)
```

---

他にもこんな感じにできます。

```{r iris_regress_kable}
library(kableExtra)
library(broom)
lm_fit %>%
  tidy() %>%
  kable(
      caption = "Regression Results",
      booktabs = TRUE,
      digits = c(2, 2, 2, 2)) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE, color = "white", background = "#0073C2")
```


# まとめ

つまり、経営学の知識、統計学の知識、それにRの知識を組み合わせれば、経営学で学んだ理論を使って仮説を考え、その仮説を検証するために必要なデータを集め、適切な統計分析手法を使い、その結果をまとめてレポート・論文にする一連のプロセスを、一カ所にまとめることができます。
さあ、Rを勉強して、統計分析と効率的なレポート・論文作成のスキルを身につけましょう。

